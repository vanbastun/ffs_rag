from pydantic import BaseModel, Field


# ===== User Request =====
class Query(BaseModel):
    """User query to RAG pipeline."""

    question: str = Field(..., description="User question text")
    top_k: int = Field(5, ge=1, le=50, description="Number of documents to return from search")


# ===== Document from Storage =====
class Document(BaseModel):
    """Document found by search or vector database."""

    id: str
    content: str
    score: float = Field(..., ge=0, description="Relevance score (higher is better)")
    metadata: dict[str, str] = Field(default_factory=dict)


# ===== Model Response =====
class Answer(BaseModel):
    """Answer generated by LLM with source support."""

    answer_text: str
    sources: list[Document] = Field(default_factory=list)


# ===== Embedding Configuration =====
class EmbeddingConfig(BaseModel):
    """Vector representation generation parameters."""

    model_name: str = "text-embedding-3-small"
    dimension: int | None = None


# ===== Retriever Configuration =====
class RetrieverConfig(BaseModel):
    """Vector database search parameters."""

    index_name: str = "default"
    similarity_threshold: float = Field(0.75, ge=0.0, le=1.0)


# ===== LLM Configuration =====
class LLMConfig(BaseModel):
    """Large Language Model settings."""

    provider: str = "openai"
    model: str = "gpt-4o-mini"
    temperature: float = Field(0.0, ge=0.0, le=2.0)
    max_tokens: int = Field(1024, ge=1)


# ===== Search Result =====
class RetrievalResult(BaseModel):
    """Retriever operation result."""

    query: Query
    documents: list[Document]


# ===== Pipeline Result =====
class PipelineResponse(BaseModel):
    """Final object returned by API."""

    query: Query
    answer: Answer
    retrieved_docs: list[Document]

Концептуальная теория для быстрого погружения в RAG

---

## 1. Что такое RAG и зачем он нужен
**Retrieval‑Augmented Generation** — это паттерн, в котором LLM не полагается только на своё обучение, а **дополняет ответ свежими и доменно‑специфичными данными** из внешних источников (БД, документов, API).

**Ключевая идея**:  
> Сначала найти релевантную информацию → затем сгенерировать ответ, используя найденное как контекст.

---

## 2. Базовая архитектура RAG

```
[Пользовательский запрос]
        │
        ▼
[Preprocessing] → нормализация, очистка
        │
        ▼
[Retrieval] → поиск релевантных чанков в векторной БД
        │
        ▼
[Augmentation] → формирование промпта с контекстом
        │
        ▼
[Generation] → LLM генерирует ответ
        │
        ▼
[Postprocessing] → форматирование, валидация
```

---

## 3. Два ключевых пайплайна

### 3.1. **Data Pipeline** (подготовка базы знаний)
1. **Сбор данных** — документы, базы, API.
2. **Очистка и нормализация** — удаление мусора, исправление кодировок.
3. **Чанкинг** — нарезка на смысловые блоки (обычно 200–500 токенов).
4. **Обогащение метаданными** — заголовки, теги, даты.
5. **Эмбеддинг** — векторизация текста.
6. **Индексирование** — сохранение в векторную БД (FAISS, Milvus, Weaviate, Pinecone).

### 3.2. **Query Pipeline** (обработка запроса)
1. **Предобработка запроса** — очистка, переформулировка.
2. **Поиск** — векторный, гибридный (BM25 + векторный), фильтры.
3. **Rerank** — переупорядочивание результатов (Cross‑Encoder).
4. **Формирование промпта** — вставка top‑N чанков в шаблон.
5. **Генерация ответа** — LLM (OpenAI, Mistral, LLaMA и др.).
6. **Постобработка** — валидация фактов, форматирование.

---

## 4. Ключевые решения при проектировании

| Этап | Вопросы для выбора | Рекомендации |
|------|-------------------|--------------|
| **Чанкинг** | Размер чанка, overlap | 200–500 токенов, overlap 10–20% |
| **Эмбеддинги** | Модель, размер вектора | OpenAI text-embedding-3-large или аналог |
| **Векторная БД** | Локально или SaaS | FAISS для локальных, Pinecone/Milvus для облака |
| **Поиск** | Векторный, BM25, гибрид | Гибрид даёт лучший recall |
| **Rerank** | Нужен ли? | Да, если важна точность top‑результатов |
| **LLM** | Модель, параметры | Подбирать под бюджет и контекстное окно |
| **Кэширование** | Что кэшировать | Эмбеддинги, retrieval, ответы |

---

## 5. Метрики качества RAG
- **Retrieval**: Recall@k, MRR, Hit Rate.
- **Generation**: Faithfulness, Answer Relevance, BLEU/ROUGE (для формализованных ответов).
- **End‑to‑End**: Пользовательские оценки, A/B‑тесты.

---

## 6. Best practices
- **Воспроизводимость**: фиксируй seed, версии моделей, конфиги.
- **Кэширование**: экономит время и деньги.
- **Логирование**: сохраняй промпты, ответы, метаданные поиска.
- **Валидация**: проверяй, что контекст действительно релевантен.
- **Fail‑safe**: если retrieval пустой — graceful degradation (LLM отвечает без контекста или сообщает об отсутствии данных).

---

## 7. Ресурсы для быстрого погружения
- [Azure Architecture Center: Design and Develop a RAG Solution](https://learn.microsoft.com/en-us/azure/architecture/ai-ml/guide/rag/rag-solution-design-and-evaluation-guide) — системный гайд от Microsoft.
- [Collabnix: RAG Complete Guide 2025](https://collabnix.com/rag-retrieval-augmented-generation-the-complete-guide-to-building-intelligent-ai-systems-in-2025/) — пошаговая инструкция с примерами.
- [Dextralabs: RAG Pipeline Explained](https://dextralabs.com/blog/rag-pipeline-explained-diagram-implementation/) — схемы и диаграммы пайплайнов.



# FFS RAG Pipeline

A production-ready RAG (Retrieval-Augmented Generation) pipeline for Fantasy Football Scout FAQ system, built with FastAPI, Qdrant, and hybrid search (dense + BM25). https://www.fantasyfootballscout.co.uk/fantasy-football-faq-and-glossary

## ğŸš€ Quick Start

### 1. Setup
```bash
# Install dependencies
make bootstrap

# Start infrastructure
make up

# Ingest data (from data/prepared/faq_prepared.json)
make ingest

# Test query
curl -X POST http://localhost:8000/v1/ask \
  -H "Content-Type: application/json" \
  -d '{"query": "What is prmium subscription?", "k": 5, "stream": false}'
```


### 2. Monitoring
- **API Docs**: http://localhost:8000/docs
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000 (admin/admin)

## ğŸ—ï¸ Project Structure

```
ffs_rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                    # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py            # API entry point
â”‚   â”‚   â”œâ”€â”€ deps.py            # Dependency injection
â”‚   â”‚   â””â”€â”€ routes/            # API endpoints
â”‚   â”‚       â”œâ”€â”€ health.py      # Health checks
â”‚   â”‚       â””â”€â”€ query.py       # RAG query endpoint
â”‚   â”œâ”€â”€ rag_core/              # Core RAG components
â”‚   â”‚   â”œâ”€â”€ __init__.py        # Main exports
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration management
â”‚   â”‚   â”œâ”€â”€ schema.py          # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ pipeline.py        # Main RAG pipeline
â”‚   â”‚   â”œâ”€â”€ storage/           # Vector stores & BM25
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ vectorstore_qdrant.py
â”‚   â”‚   â”‚   â””â”€â”€ bm25_qdrant.py
â”‚   â”‚   â”œâ”€â”€ retrieval/         # Document retrieval
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ retriever.py   # Hybrid retriever
â”‚   â”‚   â”‚   â””â”€â”€ rerankers.py   # Cross-encoder reranker
â”‚   â”‚   â”œâ”€â”€ generation/        # LLM & text generation
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ generator.py   # LLM wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ openrouter_client.py # Call to openrouter.ai API
â”‚   â”‚   â”‚   â””â”€â”€ prompting.py   # Prompt templates
â”‚   â”‚   â”œâ”€â”€ embeddings/        # Text embeddings
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ embeddings.py  # FastEmbed wrapper
â”‚   â”‚   â”œâ”€â”€ processing/        # Text processing
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ chunking.py    # Text chunking
â”‚   â”‚   â”‚   â””â”€â”€ pii.py         # PII detection
â”‚   â”‚   â””â”€â”€ observability/     # Monitoring & caching
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ observability.py # Setup Prometheus metrics
â”‚   â”‚       â””â”€â”€ caching.py     # Redis caching
â”‚   â””â”€â”€ workers/               # Background workers
â”‚       â””â”€â”€ ingest.py         # Data ingestion worker
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py           # Pytest configuration
â”‚   â”œâ”€â”€ test_ingestion.py     # Ingestion tests
â”‚   â”œâ”€â”€ test_reranker.py      # Reranker tests
â”‚   â””â”€â”€ run_tests.py          # Test runner
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ prepare_faq_data.py   # FAQ data preparation
â”‚   â”œâ”€â”€ parse_faq.py          # FAQ parsing
â”‚   â”œâ”€â”€ ingest_faq.py         # FAQ ingestion
â”‚   â””â”€â”€ docker_ingest.sh      # Docker ingestion script
â”œâ”€â”€ data/                      # Data directory
â”‚   â”œâ”€â”€ raw/                  # Raw data files
â”‚   â””â”€â”€ prepared/             # Processed data
â”‚       â””â”€â”€ faq_prepared.json # Structured FAQ data
â”œâ”€â”€ â”œâ”€â”€ docker/                # Docker configuration
â”‚   â”œâ”€â”€ docker-compose.yml    # Multi-service setup
â”‚   â”œâ”€â”€ api.Dockerfile        # API container
â”‚   â”œâ”€â”€ worker.Dockerfile     # Worker container
â”‚   â”œâ”€â”€ grafana/              # Grafana config
â”‚   â”œâ”€â”€ prometheus.yml        # Prometheus config
â”‚   â”œâ”€â”€ tempo.yaml            # Tempo config
â”‚   â””â”€â”€ otel-collector-config.yaml # OpenTelemetry config
â”œâ”€â”€ pyproject.toml            # Python dependencies
â”œâ”€â”€ Makefile                  # Build commands
â”œâ”€â”€ uv.lock                  # Dependency lock file
â”œâ”€â”€ env_example              # Environment variables template, to be replaced to .env file after git clone.
â””â”€â”€ README.md                 # This file
```

## ğŸ“‹ Complete Pipeline Walkthrough

### Step 1: Data Preparation

The pipeline starts with FAQ data preparation:

```bash
# Parse raw FAQ text into structured format
python scripts/parse_faq.py

# Generate additional questions for better coverage
python scripts/prepare_faq_data.py
```

This creates `data/prepared/faq_prepared.json` with:
- Original questions and answers
- Generated variations for better retrieval
- Structured metadata (sections, IDs)

### Step 2: Vector Store Setup

The system uses **hybrid search** combining:

**Dense Vectors (Semantic Search):**
- Uses `jinaai/jina-embeddings-v2-small-en` model
- 512-dimensional vectors
- Cosine similarity
- Stored in Qdrant collection `documents`

**BM25 (Keyword Search):**
- Sparse vectors with IDF weighting
- Exact keyword matching
- Stored in Qdrant collection `bm25_documents`
- Multiple entries per FAQ (original + generated questions)

### Step 3: Ingestion Process

```bash
python -m src.workers.ingest
```

The ingestion process:

1. **Loads FAQ data** from `faq_prepared.json`
2. **Creates dense vectors** for each FAQ item (Q + A)
3. **Creates BM25 documents** for all questions (original + generated)
4. **Stores in Qdrant** with proper metadata
5. **Reports statistics** on created vectors/documents

### Step 4: Query Processing

When a query comes in:

1. **Embedding Generation**: Query â†’ dense vector
2. **Hybrid Retrieval**:
   - Dense search in `documents` collection
   - BM25 search in `bm25_documents` collection
   - Score fusion with configurable alpha (default: 0.5)
3. **Reranking**: Cross-encoder reranker improves relevance
4. **Generation**: LLM generates answer from retrieved context
5. **Response**: Structured JSON response

## ğŸ› ï¸ Development

### Running Tests

```bash
# Run all tests
make test

# Run specific test
python tests/test_reranker.py
python tests/test_ingestion.py

# Run with pytest directly
pytest tests/ -v
```

### Code Quality

```bash
# Lint code
make lint

# Format code
make format

# Type checking
make typecheck
```

### Docker Development

```bash
# Build and run in Docker
make up

# Run ingestion in Docker
./scripts/docker_ingest.sh

# Stop services
make down
```

## âš™ï¸ Configuration

### Environment Variables

```bash
# Core settings
RAG_QDRANT_URL=http://localhost:6333
RAG_REDIS_URL=redis://localhost:6379/0

# Models
RAG_EMBEDDING_MODEL=jinaai/jina-embeddings-v2-small-en
RAG_RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# LLM (optional)
OPENROUTER_API_KEY=your_key_here
OPENROUTER_MODEL=deepseek/deepseek-r1-0528:free
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **Qdrant Connection Error**
   ```bash
   # Check if Qdrant is running
   curl http://localhost:6333/health

   # Restart Qdrant
   docker-compose -f docker/docker-compose.yml restart qdrant
   ```

2. **Missing Dependencies**
   ```bash
   # Reinstall dependencies
   pip install -e .
   ```

3. **Empty Collections**
   ```bash
   # Re-run ingestion
   make ingest
   ```

### Logs

```bash
# View API logs
docker-compose -f docker/docker-compose.yml logs api

# View worker logs
docker-compose -f docker/docker-compose.yml logs worker

# View all logs
docker-compose -f docker/docker-compose.yml logs -f
```
